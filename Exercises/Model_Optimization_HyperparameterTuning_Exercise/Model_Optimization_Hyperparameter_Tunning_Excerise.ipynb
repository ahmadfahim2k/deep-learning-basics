{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS_V6StcOXOr"
      },
      "source": [
        "# Problem Statement: **Hyperparameter Tuning for AtliQ’s Fashion Item Classifier**\n",
        "\n",
        "### AtliQ Fashion wants to develop a neural network to classify fashion items using the FashionMNIST dataset. Your task is to optimize the neural network's performance by fine-tuning its hyperparameters. We will be using **FashionMNIST** dataset but since the dataset is large, we will work with only a subset to ensure that the solution is computationally feasible.\n",
        "\n",
        "**References:**\n",
        "\n",
        "* transforms.Compose (PyTorch): [Link](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html)\n",
        "* Optuna (Hyperparameter Optimization Framework) [Link](https://optuna.readthedocs.io/en/stable/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nv9L_r8yOjoo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import optuna\n",
        "import random\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65TpZ6z3YVcT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBrkVANZOnea"
      },
      "source": [
        "**Dataset Overview**\n",
        "\n",
        "* Dataset: FashionMNIST\n",
        "* Classes: 10 (e.g., T-shirts, trousers, shoes)\n",
        "* Training Images: Subset of 10,000 (randomly sampled from 60,000)\n",
        "* Test Images: Subset of 2,000 (randomly sampled from 10,000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJiS4LzoYWh9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caIjvjTMOuKb"
      },
      "source": [
        "**Step1**: Load and Sample the Dataset\n",
        "\n",
        "* Load the FashionMNIST dataset using torchvision.datasets.\n",
        "* Sample 10,000 images for training and 2,000 images for testing.\n",
        "* Normalize the pixel values to the range [-1, 1].\n",
        "* Create PyTorch DataLoaders for the training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4ESYRM7JK-UW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 34.7MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 1.14MB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 17.1MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<?, ?B/s]\n"
          ]
        }
      ],
      "source": [
        "# Transform: Normalize and convert to tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Centers the pixel values around 0 and scales them to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load FashionMNIST dataset\n",
        "\n",
        "dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "# Sample the datset\n",
        "\n",
        "train_subset_size = 10_000\n",
        "test_subset_size = 2_000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9NJ-ejsYYU7"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbAUaSPmSfsZ"
      },
      "source": [
        "**Step2**: Create Dataloaders\n",
        "\n",
        "* batch size = 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xPPkBtqbacNM"
      },
      "outputs": [],
      "source": [
        "train_subset, _ = random_split(dataset, [train_subset_size, len(dataset) - train_subset_size])\n",
        "test_subset, _ = random_split(test_dataset, [test_subset_size, len(test_dataset) - test_subset_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hz00fg0sSqT2"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_subset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oq15WEfhS1HV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data size: 10000\n",
            "Testing data size: 2000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training data size: {len(train_subset)}\")\n",
        "print(f\"Testing data size: {len(test_subset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dSLUp9EYaG9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGRSPjG0StuU"
      },
      "source": [
        "**Step3**: Define the Neural Network\n",
        "\n",
        "* Create a fully connected feed-forward neural network (no CNN).\n",
        "\n",
        "Structure:\n",
        "* Input layer: 784 neurons (28x28 image flattened).\n",
        "* 1st hidden layer: 128 neurons with ReLU activation.\n",
        "* 2nd hidden layer: 64 neurons with ReLU activation.\n",
        "* Output layer: 10 neurons (one for each class) with Softmax activation.\n",
        "\n",
        "Use `nn.Sequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QJYOKAZmTpkb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FashionNN(\n",
            "  (network): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=64, out_features=10, bias=True)\n",
            "    (6): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class FashionNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            # Flatten the input tensor\n",
        "            nn.Flatten(),\n",
        "            # Input layer (784)\n",
        "            nn.Linear(28*28, 128),\n",
        "            # Activation\n",
        "            nn.ReLU(),\n",
        "            # Hidden layer 1\n",
        "            nn.Linear(128, 64),\n",
        "            # Activation\n",
        "            nn.ReLU(),\n",
        "            # Output layer (10 classes)\n",
        "            nn.Linear(64, 10),\n",
        "            # Softmax for probabilities\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "model = FashionNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJmkGAINYb0C"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNO5O1W_UI7L"
      },
      "source": [
        "**Step 3**: Train the Base Model\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Set the following base hyperparameters:\n",
        "* Loss function: Cross Entropy Loss\n",
        "* Learning rate: 0.01\n",
        "* Batch size: 32\n",
        "* Optimizer: SGD\n",
        "* Epochs: 100\n",
        "\n",
        "Train the model and record the training/validation accuracy and loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Mb5gFuiUUTDC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Loss: 2.2967\n",
            "Epoch 2/100, Loss: 2.2744\n",
            "Epoch 3/100, Loss: 2.2111\n",
            "Epoch 4/100, Loss: 2.1132\n",
            "Epoch 5/100, Loss: 2.0172\n",
            "Epoch 6/100, Loss: 1.9569\n",
            "Epoch 7/100, Loss: 1.9202\n",
            "Epoch 8/100, Loss: 1.8718\n",
            "Epoch 9/100, Loss: 1.8300\n",
            "Epoch 10/100, Loss: 1.8085\n",
            "Epoch 11/100, Loss: 1.7948\n",
            "Epoch 12/100, Loss: 1.7553\n",
            "Epoch 13/100, Loss: 1.7275\n",
            "Epoch 14/100, Loss: 1.7165\n",
            "Epoch 15/100, Loss: 1.7089\n",
            "Epoch 16/100, Loss: 1.7031\n",
            "Epoch 17/100, Loss: 1.6984\n",
            "Epoch 18/100, Loss: 1.6944\n",
            "Epoch 19/100, Loss: 1.6910\n",
            "Epoch 20/100, Loss: 1.6880\n",
            "Epoch 21/100, Loss: 1.6853\n",
            "Epoch 22/100, Loss: 1.6828\n",
            "Epoch 23/100, Loss: 1.6806\n",
            "Epoch 24/100, Loss: 1.6784\n",
            "Epoch 25/100, Loss: 1.6764\n",
            "Epoch 26/100, Loss: 1.6745\n",
            "Epoch 27/100, Loss: 1.6727\n",
            "Epoch 28/100, Loss: 1.6709\n",
            "Epoch 29/100, Loss: 1.6692\n",
            "Epoch 30/100, Loss: 1.6676\n",
            "Epoch 31/100, Loss: 1.6661\n",
            "Epoch 32/100, Loss: 1.6646\n",
            "Epoch 33/100, Loss: 1.6632\n",
            "Epoch 34/100, Loss: 1.6618\n",
            "Epoch 35/100, Loss: 1.6605\n",
            "Epoch 36/100, Loss: 1.6593\n",
            "Epoch 37/100, Loss: 1.6581\n",
            "Epoch 38/100, Loss: 1.6570\n",
            "Epoch 39/100, Loss: 1.6559\n",
            "Epoch 40/100, Loss: 1.6549\n",
            "Epoch 41/100, Loss: 1.6540\n",
            "Epoch 42/100, Loss: 1.6530\n",
            "Epoch 43/100, Loss: 1.6521\n",
            "Epoch 44/100, Loss: 1.6513\n",
            "Epoch 45/100, Loss: 1.6504\n",
            "Epoch 46/100, Loss: 1.6496\n",
            "Epoch 47/100, Loss: 1.6488\n",
            "Epoch 48/100, Loss: 1.6481\n",
            "Epoch 49/100, Loss: 1.6473\n",
            "Epoch 50/100, Loss: 1.6466\n",
            "Epoch 51/100, Loss: 1.6459\n",
            "Epoch 52/100, Loss: 1.6452\n",
            "Epoch 53/100, Loss: 1.6445\n",
            "Epoch 54/100, Loss: 1.6438\n",
            "Epoch 55/100, Loss: 1.6432\n",
            "Epoch 56/100, Loss: 1.6425\n",
            "Epoch 57/100, Loss: 1.6419\n",
            "Epoch 58/100, Loss: 1.6413\n",
            "Epoch 59/100, Loss: 1.6407\n",
            "Epoch 60/100, Loss: 1.6401\n",
            "Epoch 61/100, Loss: 1.6395\n",
            "Epoch 62/100, Loss: 1.6390\n",
            "Epoch 63/100, Loss: 1.6385\n",
            "Epoch 64/100, Loss: 1.6379\n",
            "Epoch 65/100, Loss: 1.6374\n",
            "Epoch 66/100, Loss: 1.6369\n",
            "Epoch 67/100, Loss: 1.6364\n",
            "Epoch 68/100, Loss: 1.6360\n",
            "Epoch 69/100, Loss: 1.6355\n",
            "Epoch 70/100, Loss: 1.6350\n",
            "Epoch 71/100, Loss: 1.6346\n",
            "Epoch 72/100, Loss: 1.6341\n",
            "Epoch 73/100, Loss: 1.6337\n",
            "Epoch 74/100, Loss: 1.6333\n",
            "Epoch 75/100, Loss: 1.6328\n",
            "Epoch 76/100, Loss: 1.6324\n",
            "Epoch 77/100, Loss: 1.6320\n",
            "Epoch 78/100, Loss: 1.6316\n",
            "Epoch 79/100, Loss: 1.6312\n",
            "Epoch 80/100, Loss: 1.6309\n",
            "Epoch 81/100, Loss: 1.6305\n",
            "Epoch 82/100, Loss: 1.6301\n",
            "Epoch 83/100, Loss: 1.6297\n",
            "Epoch 84/100, Loss: 1.6293\n",
            "Epoch 85/100, Loss: 1.6290\n",
            "Epoch 86/100, Loss: 1.6286\n",
            "Epoch 87/100, Loss: 1.6283\n",
            "Epoch 88/100, Loss: 1.6279\n",
            "Epoch 89/100, Loss: 1.6276\n",
            "Epoch 90/100, Loss: 1.6273\n",
            "Epoch 91/100, Loss: 1.6269\n",
            "Epoch 92/100, Loss: 1.6266\n",
            "Epoch 93/100, Loss: 1.6263\n",
            "Epoch 94/100, Loss: 1.6260\n",
            "Epoch 95/100, Loss: 1.6257\n",
            "Epoch 96/100, Loss: 1.6254\n",
            "Epoch 97/100, Loss: 1.6251\n",
            "Epoch 98/100, Loss: 1.6248\n",
            "Epoch 99/100, Loss: 1.6245\n",
            "Epoch 100/100, Loss: 1.6243\n"
          ]
        }
      ],
      "source": [
        "# Define loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(params=model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    model.train()  # Set model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = model(images)\n",
        "        loss = loss_function(predictions, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Append the training loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAu40Az5itQY"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZBFzIaZU3gU"
      },
      "source": [
        "**Step 4**: Perform Hyperparameter Tuning\n",
        "Instructions:\n",
        "\n",
        "**Grid Search:**\n",
        "\n",
        "Hyperparameters:\n",
        "* Learning rate: [0.001, 0.01, 0.1]\n",
        "* Batch size: [32, 64]\n",
        "* Evaluate all combinations systematically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TcJybSHKVSu1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR: 0.001, Batch size: 32, Loss: 1.6239\n",
            "LR: 0.001, Batch size: 64, Loss: 1.6242\n",
            "LR: 0.01, Batch size: 32, Loss: 1.6255\n",
            "LR: 0.01, Batch size: 64, Loss: 1.6245\n",
            "LR: 0.1, Batch size: 32, Loss: 1.6599\n",
            "LR: 0.1, Batch size: 64, Loss: 1.6370\n",
            "Best Params (Grid Search): {'lr': 0.001, 'batch_size': 32}\n"
          ]
        }
      ],
      "source": [
        "# Define grid search parameters\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "batch_sizes = [32, 64]\n",
        "\n",
        "# Train and evaluate for all combinations\n",
        "best_loss = float('inf')\n",
        "best_params = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        optimizer = optim.SGD(params=model.parameters(), lr=lr)\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "        train_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            # Code Here\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            pred = model(images)\n",
        "            loss = loss_function(pred, labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "        print(f\"LR: {lr}, Batch size: {batch_size}, Loss: {avg_loss:.4f}\")\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_params = {'lr': lr, 'batch_size': batch_size}\n",
        "\n",
        "print(f\"Best Params (Grid Search): {best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-oxYMQFiuwX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZBDWk_wV3hB"
      },
      "source": [
        "**Random Search:**\n",
        "\n",
        "Randomly select hyperparameters for 5 trials from:\n",
        "* Learning rate: [0.0001, 0.001, 0.01, 0.1]\n",
        "* Batch size: [16, 32, 64, 128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Tpbk9NjpV5GI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR: 0.01, Batch size: 16, Loss: 1.6272\n",
            "LR: 0.01, Batch size: 32, Loss: 1.6233\n",
            "LR: 0.01, Batch size: 64, Loss: 1.6222\n",
            "LR: 0.01, Batch size: 128, Loss: 1.6203\n",
            "LR: 0.1, Batch size: 16, Loss: 1.6781\n",
            "LR: 0.1, Batch size: 32, Loss: 1.6418\n",
            "LR: 0.1, Batch size: 64, Loss: 1.6314\n",
            "LR: 0.1, Batch size: 128, Loss: 1.6252\n",
            "LR: 0.1, Batch size: 16, Loss: 1.6589\n",
            "LR: 0.1, Batch size: 32, Loss: 1.6345\n",
            "LR: 0.1, Batch size: 64, Loss: 1.6275\n",
            "LR: 0.1, Batch size: 128, Loss: 1.6211\n",
            "LR: 0.0001, Batch size: 16, Loss: 1.6374\n",
            "LR: 0.0001, Batch size: 32, Loss: 1.6320\n",
            "LR: 0.0001, Batch size: 64, Loss: 1.6305\n",
            "LR: 0.0001, Batch size: 128, Loss: 1.6286\n",
            "LR: 0.01, Batch size: 16, Loss: 1.6193\n",
            "LR: 0.01, Batch size: 32, Loss: 1.6167\n",
            "LR: 0.01, Batch size: 64, Loss: 1.6161\n",
            "LR: 0.01, Batch size: 128, Loss: 1.6153\n",
            "Best Params (Random Search): {'lr': 0.01, 'batch_size': 128}\n"
          ]
        }
      ],
      "source": [
        "# Define random search space\n",
        "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
        "batch_sizes = [16, 32, 64, 128]\n",
        "# Randomly sample 5 combinations\n",
        "for _ in range(5):\n",
        "    lr = random.choice(learning_rates)\n",
        "    batch_size = random.choice(batch_sizes)\n",
        "    for batch_size in batch_sizes:\n",
        "        optimizer = optim.SGD(params=model.parameters(), lr=lr)\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "        train_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            # Code Here\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            pred = model(images)\n",
        "            loss = loss_function(pred, labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "\n",
        "\n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "        print(f\"LR: {lr}, Batch size: {batch_size}, Loss: {avg_loss:.4f}\")\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_params = {'lr': lr, 'batch_size': batch_size}\n",
        "\n",
        "print(f\"Best Params (Random Search): {best_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ewVlxfjiv9L"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u46y5GicWU4Y"
      },
      "source": [
        "**Bayesian Optimization (Optuna):**\n",
        "\n",
        "Use optuna.create_study to dynamically suggest:\n",
        "* Learning rate: Range (0.0001, 0.1)\n",
        "* Hidden layer neurons: Range (32, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8pX7C-hQWYzu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-01-01 18:05:48,501] A new study created in memory with name: no-name-d34326a5-5c2b-44e4-aa61-d6c635990174\n",
            "C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_10676\\86044101.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
            "[I 2026-01-01 18:05:54,294] Trial 0 finished with value: 2.229834238688151 and parameters: {'learning_rate': 0.004734281213607744, 'hidden_dim': 152}. Best is trial 0 with value: 2.229834238688151.\n",
            "[I 2026-01-01 18:06:00,036] Trial 1 finished with value: 2.0424945089552136 and parameters: {'learning_rate': 0.01241108871773165, 'hidden_dim': 203}. Best is trial 1 with value: 2.0424945089552136.\n",
            "[I 2026-01-01 18:06:05,698] Trial 2 finished with value: 2.2610787853362067 and parameters: {'learning_rate': 0.0037521805976046155, 'hidden_dim': 234}. Best is trial 1 with value: 2.0424945089552136.\n",
            "[I 2026-01-01 18:06:11,428] Trial 3 finished with value: 2.2975469354599243 and parameters: {'learning_rate': 0.00040156356138318594, 'hidden_dim': 80}. Best is trial 1 with value: 2.0424945089552136.\n",
            "[I 2026-01-01 18:06:17,078] Trial 4 finished with value: 2.278744758121551 and parameters: {'learning_rate': 0.0023951487509757882, 'hidden_dim': 121}. Best is trial 1 with value: 2.0424945089552136.\n",
            "[I 2026-01-01 18:06:22,830] Trial 5 finished with value: 2.1726044359661283 and parameters: {'learning_rate': 0.006651870927917217, 'hidden_dim': 232}. Best is trial 1 with value: 2.0424945089552136.\n",
            "[I 2026-01-01 18:06:28,629] Trial 6 finished with value: 1.9319098828330872 and parameters: {'learning_rate': 0.02145343675611643, 'hidden_dim': 185}. Best is trial 6 with value: 1.9319098828330872.\n",
            "[I 2026-01-01 18:06:34,425] Trial 7 finished with value: 2.304779056518797 and parameters: {'learning_rate': 0.00017744915556809407, 'hidden_dim': 191}. Best is trial 6 with value: 1.9319098828330872.\n",
            "[I 2026-01-01 18:06:40,335] Trial 8 finished with value: 2.2809421486324735 and parameters: {'learning_rate': 0.002589392828189731, 'hidden_dim': 90}. Best is trial 6 with value: 1.9319098828330872.\n",
            "[I 2026-01-01 18:06:46,475] Trial 9 finished with value: 2.2932809875124978 and parameters: {'learning_rate': 0.0011266539991397128, 'hidden_dim': 246}. Best is trial 6 with value: 1.9319098828330872.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Params (Optuna): {'learning_rate': 0.02145343675611643, 'hidden_dim': 185}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest parameters\n",
        "    lr = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
        "    neurons = trial.suggest_int('hidden_dim', 32, 256)\n",
        "\n",
        "    # Modify model\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(28*28, neurons),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(neurons, 10),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "    optimizer = optim.SGD(params=model.parameters(), lr=lr)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train model\n",
        "    model.train()\n",
        "    num_epochs = 5\n",
        "    for epoch in range(num_epochs):\n",
        "        for images, labels in train_loader:\n",
        "            # Flatten images\n",
        "            images = images.view(images.size(0), -1)\n",
        "            \n",
        "            # Forward pass\n",
        "            pred = model(images)\n",
        "            loss = loss_function(pred, labels)\n",
        "            \n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            # Flatten images\n",
        "            images = images.view(images.size(0), -1)\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(images)\n",
        "            loss = loss_function(predictions, labels)\n",
        "\n",
        "            # Append the total_loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)  # Average loss over all batches\n",
        "    return avg_loss  # Return loss for Optuna to minimize\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "print(f\"Best Params (Optuna): {study.best_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhLh1t7LYnmj"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAkXzAgHW9wQ"
      },
      "source": [
        "**Step5**: Evaluate and Compare the Model\n",
        "\n",
        "* Train the model using the best hyperparameters from each method (Grid Search, Random Search, Optuna).\n",
        "* num_epochs = 50\n",
        "* Evaluate all models on the test set.\n",
        "* Plot training/validation accuracy and loss for the best model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aMRSKltYXPTD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 2.2798\n",
            "Epoch 2/50, Loss: 2.1313\n",
            "Epoch 3/50, Loss: 1.9814\n",
            "Epoch 4/50, Loss: 1.8669\n",
            "Epoch 5/50, Loss: 1.8171\n",
            "Epoch 6/50, Loss: 1.7927\n",
            "Epoch 7/50, Loss: 1.7786\n",
            "Epoch 8/50, Loss: 1.7519\n",
            "Epoch 9/50, Loss: 1.7108\n",
            "Epoch 10/50, Loss: 1.6987\n",
            "Epoch 11/50, Loss: 1.6908\n",
            "Epoch 12/50, Loss: 1.6845\n",
            "Epoch 13/50, Loss: 1.6793\n",
            "Epoch 14/50, Loss: 1.6748\n",
            "Epoch 15/50, Loss: 1.6710\n",
            "Epoch 16/50, Loss: 1.6676\n",
            "Epoch 17/50, Loss: 1.6645\n",
            "Epoch 18/50, Loss: 1.6617\n",
            "Epoch 19/50, Loss: 1.6592\n",
            "Epoch 20/50, Loss: 1.6569\n",
            "Epoch 21/50, Loss: 1.6548\n",
            "Epoch 22/50, Loss: 1.6530\n",
            "Epoch 23/50, Loss: 1.6512\n",
            "Epoch 24/50, Loss: 1.6496\n",
            "Epoch 25/50, Loss: 1.6480\n",
            "Epoch 26/50, Loss: 1.6465\n",
            "Epoch 27/50, Loss: 1.6450\n",
            "Epoch 28/50, Loss: 1.6437\n",
            "Epoch 29/50, Loss: 1.6425\n",
            "Epoch 30/50, Loss: 1.6413\n",
            "Epoch 31/50, Loss: 1.6402\n",
            "Epoch 32/50, Loss: 1.6392\n",
            "Epoch 33/50, Loss: 1.6383\n",
            "Epoch 34/50, Loss: 1.6374\n",
            "Epoch 35/50, Loss: 1.6365\n",
            "Epoch 36/50, Loss: 1.6357\n",
            "Epoch 37/50, Loss: 1.6349\n",
            "Epoch 38/50, Loss: 1.6342\n",
            "Epoch 39/50, Loss: 1.6334\n",
            "Epoch 40/50, Loss: 1.6327\n",
            "Epoch 41/50, Loss: 1.6320\n",
            "Epoch 42/50, Loss: 1.6314\n",
            "Epoch 43/50, Loss: 1.6307\n",
            "Epoch 44/50, Loss: 1.6301\n",
            "Epoch 45/50, Loss: 1.6294\n",
            "Epoch 46/50, Loss: 1.6288\n",
            "Epoch 47/50, Loss: 1.6282\n",
            "Epoch 48/50, Loss: 1.6277\n",
            "Epoch 49/50, Loss: 1.6271\n",
            "Epoch 50/50, Loss: 1.6266\n",
            "Test Loss: 1.6670\n",
            "Test Accuracy: 79.75%\n"
          ]
        }
      ],
      "source": [
        "# Train model with best params and evaluate\n",
        "model = FashionNN()  # Re-initialize the model\n",
        "optimizer = optim.SGD(params=model.parameters(), lr=study.best_params['learning_rate'])\n",
        "train_loader = DataLoader(train_subset, batch_size=32)\n",
        "\n",
        "# Define loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50 # Re-train with best parameters\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    model.train()  # Set model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        # Clear previous gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = model(images)\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = loss_function(predictions, labels)\n",
        "        \n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "model.eval()  # Set model to evaluation mode\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for evaluation\n",
        "    for images, labels in test_loader:\n",
        "        predictions = model(images)\n",
        "        loss = loss_function(predictions, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(predictions, 1)  # Get class with highest probability\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Print test loss and accuracy\n",
        "print(f\"Test Loss: {test_loss/len(test_loader):.4f}\")\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4LgAqQ1Yo7_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0sNkV7nYsZf"
      },
      "source": [
        "**Step6**: Visualize the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "W1TNb1LaYwq1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get predictions\n",
        "model.eval()\n",
        "images, labels = next(iter(test_loader))\n",
        "predictions = model(images).argmax(dim=1)\n",
        "\n",
        "# Plot 9 images\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"Pred: {predictions[i]}, True: {labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
