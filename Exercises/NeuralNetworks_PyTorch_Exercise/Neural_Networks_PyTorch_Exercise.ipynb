{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh8Jc28NWy7Z"
      },
      "source": [
        "# Problem Statement: **Threat Classification for AtliQ Wildlife Reserve**\n",
        "\n",
        "### Welcome to the AtliQ Wildlife Reserve, a sanctuary where technology helps preserve wildlife. You are tasked with developing AI systems to monitor, classify, and predict behaviors of animals in the sanctuary.\n",
        "\n",
        "\n",
        "**References:**\n",
        "\n",
        "* PyTorch Dataset and Dataloader [link](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
        "* Seaborn Heatmaps [link](https://seaborn.pydata.org/generated/seaborn.heatmap.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5MqurUZXGoU"
      },
      "source": [
        "Imports and CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "9kq7PLN6WEo3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXD3uwVpHjMc"
      },
      "source": [
        "## Let's do some revision first!\n",
        "\n",
        "**Problem1.** AtliQ Warehouse\n",
        "\n",
        "Your task is to define a simple neural network that will predict whether AtliQ's warehouses are running an optimal stock level for a given product (binary classification). The neural network should include:\n",
        "\n",
        "* An input layer of size 128 (representing features such as sales trends, regional demand, and supplier reliability).\n",
        "* Two hidden layers, each with 64 neurons.\n",
        "* An output layer that predicts the stock status (1 for optimal, 0 for not optimal).\n",
        "\n",
        "\n",
        "**Hint:** Use nn.Sequential to define the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "VruFTaiIHm9Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "   # Code Here\n",
        "   nn.Linear(128, 64),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(64, 64),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(64, 2),\n",
        ")\n",
        "\n",
        "# Print the model structure\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKM7R8qtISyy"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ye_04NuH5Ms"
      },
      "source": [
        "**Problem2.** Sales data at AtliQ\n",
        "\n",
        "AtliQ's data analytics team has provided sales data in NumPy format for your AI models. The data,\n",
        "\n",
        "` data = np.array([1, 2, 3, 4, 5])`,\n",
        "\n",
        " represents product sales in a given week. Your task is to:\n",
        "\n",
        "Convert this NumPy array into a PyTorch tensor of type float32.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "KA0qDRm2H9HH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3., 4., 5.])\n"
          ]
        }
      ],
      "source": [
        "# Create a NumPy array\n",
        "data = np.array([1,2,3,4,5])\n",
        "\n",
        "# Convert the NumPy array to a PyTorch tensor of type float32\n",
        "tensor_data = torch.tensor(data, dtype=torch.float32)\n",
        "\n",
        "# Print the tensor\n",
        "print(tensor_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA20Ywx9IT6-"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWUBNL9hIE9B"
      },
      "source": [
        "**Problem3.** Customer Classification at AtliQ\n",
        "\n",
        "AtliQ's marketing team is running an AI model to classify customers into 3 distinct segments based on purchasing behavior. Your task is to:\n",
        "\n",
        "* Simulate raw logits from the model's output.\n",
        "* Generate random target labels for a 3-class classification task\n",
        "* Compute the classification loss using nn.CrossEntropyLoss\n",
        "\n",
        "**Hint**: Use torch.randint() for generating random target labels and nn.CrossEntropyLoss() for the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "frkwQz0vIGxS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Entropy Loss: 1.0845\n"
          ]
        }
      ],
      "source": [
        "logits = torch.tensor([[1.0, 2.0, 0.5], [1.5, 0.2, 1.7], [0.4, 0.8, 2.1]], dtype=torch.float32)\n",
        "\n",
        "labels = torch.tensor([1, 2, 0], dtype=torch.long)\n",
        "\n",
        "# Define the CrossEntropyLoss function\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "# Compute the loss\n",
        "loss = loss_fun(logits, labels)\n",
        "\n",
        "print(f\"Cross-Entropy Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSO1nyKkCKmI"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cg8Swd2YAWD"
      },
      "source": [
        "### **Task:** Habitat Threat Detector\n",
        "\n",
        "In the sanctuary, camera drones monitor animal habitats for threats like poaching activities or habitat damage. Your task as an AI Engineer is to build an AI system to detect whether an image shows a threat from the provided dataset **(habitat_images_codebasics_DL.csv)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIokYWC0YP4L"
      },
      "source": [
        "**Dataset Overview**\n",
        "\n",
        "The dataset **habitat_images_codebasics_DL.csv** contains the following features:\n",
        "\n",
        "* Image Brightness (float): Represents how bright or dark the image is.\n",
        "* Movement Intensity (float): Measures activity detected in the image.\n",
        "* Number of Shapes Detected (integer): Indicates potential objects in the image.\n",
        "* Noise Level (float): A measure of distortions in the image.\n",
        "* Threat Label (0 or 1): 0 for no threat, 1 for a threat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_9Qhmdfb-i6"
      },
      "source": [
        "**Step 1:** Load and Split the Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Brightness</th>\n",
              "      <th>Movement Intensity</th>\n",
              "      <th>Number of Shapes Detected</th>\n",
              "      <th>Noise Level</th>\n",
              "      <th>Threat Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.437086</td>\n",
              "      <td>0.314292</td>\n",
              "      <td>19</td>\n",
              "      <td>0.186741</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.955643</td>\n",
              "      <td>6.364104</td>\n",
              "      <td>10</td>\n",
              "      <td>4.113003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.758795</td>\n",
              "      <td>3.143560</td>\n",
              "      <td>16</td>\n",
              "      <td>1.800953</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.638793</td>\n",
              "      <td>5.085707</td>\n",
              "      <td>7</td>\n",
              "      <td>0.635303</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.240417</td>\n",
              "      <td>9.075665</td>\n",
              "      <td>3</td>\n",
              "      <td>2.611216</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Image Brightness  Movement Intensity  Number of Shapes Detected  \\\n",
              "0          0.437086            0.314292                         19   \n",
              "1          0.955643            6.364104                         10   \n",
              "2          0.758795            3.143560                         16   \n",
              "3          0.638793            5.085707                          7   \n",
              "4          0.240417            9.075665                          3   \n",
              "\n",
              "   Noise Level  Threat Label  \n",
              "0     0.186741             0  \n",
              "1     4.113003             0  \n",
              "2     1.800953             0  \n",
              "3     0.635303             0  \n",
              "4     2.611216             0  "
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"habitat_images_codebasics_DL.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "Rogs1y3WZetS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Separate input features and labels\n",
        "X = df[['Image Brightness', 'Movement Intensity', 'Number of Shapes Detected', 'Noise Level']].values\n",
        "y = df[['Threat Label']].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vNDgGL0CgGg"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEeQyboLTPp7"
      },
      "source": [
        "**Step 2:** Normalize the input feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "pIGSwZ2BTUbI"
      },
      "outputs": [],
      "source": [
        "X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6bZjpy1CNsy"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiDwdn7ATcTZ"
      },
      "source": [
        "**Step3:** Convert to PyTorch tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "adHSY6CYTlyT"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Reshape to match the model output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4liDHApDCOZS"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4qB9eZCTmVj"
      },
      "source": [
        "**Step4**: Perform an **70%-30%** train-validation split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "oW355OZ2TnEf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8vOlfDOCSP_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqR6Q2xXT9kN"
      },
      "source": [
        "**Step5**: Create DataLoader for batch processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "hfVYt4wRUAgV"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(X_train, y_train)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEEbzWfpCWJd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MZtV-f_cMi9"
      },
      "source": [
        "**Step 6:** Define the Neural Network\n",
        "\n",
        "* Input layer with 4 features.\n",
        "* One hidden layer with 8 neurons (ReLU activation).\n",
        "* Output layer with 1 neuron (Sigmoid activation for binary classification)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "OzjTQoEYcXv-"
      },
      "outputs": [],
      "source": [
        "class ThreatDetector(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ThreatDetector, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(4, 8),    # Input: 4 features, Hidden layer: 8 neurons\n",
        "            nn.ReLU(),          # Activation: ReLU\n",
        "            nn.Linear(8, 1),    # Output: 1 neuron\n",
        "            nn.Sigmoid()        # Activation: Sigmoid (for binary classification)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Instantiate the model\n",
        "model = ThreatDetector()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdGIL4AgCXbO"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geUtDQ-AUghS"
      },
      "source": [
        "**Step7**: Define Loss and Optimizer\n",
        "\n",
        "* Optimizer: Adam\n",
        "* Loss: BCE Loss\n",
        "* Learning rate: 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "0lCy2REGUl5A"
      },
      "outputs": [],
      "source": [
        "# Binary Cross-Entropy Loss\n",
        "BCE_loss = nn.BCELoss()\n",
        "\n",
        "# Adam Optimizer\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.01)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhvb58nVCY1M"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMDovUEJcZe0"
      },
      "source": [
        "**Step 8**: Train the Neural Network\n",
        "\n",
        "* Train the model for 20 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "edU_flFQdgMH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 0.5484\n",
            "Epoch 2/20, Loss: 0.5150\n",
            "Epoch 3/20, Loss: 0.4654\n",
            "Epoch 4/20, Loss: 0.3958\n",
            "Epoch 5/20, Loss: 0.3538\n",
            "Epoch 6/20, Loss: 0.3277\n",
            "Epoch 7/20, Loss: 0.3575\n",
            "Epoch 8/20, Loss: 0.3093\n",
            "Epoch 9/20, Loss: 0.3022\n",
            "Epoch 10/20, Loss: 0.2996\n",
            "Epoch 11/20, Loss: 0.2979\n",
            "Epoch 12/20, Loss: 0.2922\n",
            "Epoch 13/20, Loss: 0.2894\n",
            "Epoch 14/20, Loss: 0.2865\n",
            "Epoch 15/20, Loss: 0.2806\n",
            "Epoch 16/20, Loss: 0.2803\n",
            "Epoch 17/20, Loss: 0.3158\n",
            "Epoch 18/20, Loss: 0.2741\n",
            "Epoch 19/20, Loss: 0.3105\n",
            "Epoch 20/20, Loss: 0.3430\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, train_loader, BCE_loss, optimizer, epochs=20):\n",
        "    # Code Here\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            \n",
        "            labels = labels.float().view(labels.size(0), 1)   # [B, 1]\n",
        "            \n",
        "            # Forward pass\n",
        "            pred = model(images)\n",
        "            loss = BCE_loss(pred, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Accumulate loss\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, BCE_loss, optimizer, epochs=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGsCOWreCZ2F"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7YoTEEddiwA"
      },
      "source": [
        "**Step 9:** Evaluate the Model\n",
        "\n",
        "* Calculate the accuracy and loss on a test dataset.\n",
        "* Use a confusion matrix to evaluate the systemâ€™s performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "rxDluCzUWBls"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.00\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    # Code Here\n",
        "    model.eval()\n",
        "    \n",
        "    y_pred_list = []\n",
        "    y_true_list = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            pred = model(images)\n",
        "            \n",
        "            # move to CPU and flatten\n",
        "            pred = pred.cpu().view(-1)    # [B]\n",
        "            labels = labels.cpu().view(-1)  # [B]\n",
        "            \n",
        "            y_pred_list.extend(pred.tolist())\n",
        "            y_true_list.extend(labels.tolist())\n",
        "            \n",
        "\n",
        "    # Convert predictions to binary (threshold = 0.5)\n",
        "    y_pred_binary = [1 if val>0.5  else 0 for val in y_pred_list]\n",
        "    y_true_binary = [int(t) for t in y_true_list]\n",
        "    # Accuracy\n",
        "    accuracy = accuracy_score(y_true_list, y_true_binary)\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true_list, y_true_binary)\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2inPw3AICa1E"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
